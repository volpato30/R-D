{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import pickle\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for j in range(5):\n",
    "        d = unpickle('cifar-10-batches-py/data_batch_'+`j+1`)\n",
    "        x = d['data']\n",
    "        y = d['labels']\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    d = unpickle('cifar-10-batches-py/test_batch')\n",
    "    xs.append(d['data'])\n",
    "    ys.append(d['labels'])\n",
    "\n",
    "    x = np.concatenate(xs)/np.float32(255)\n",
    "    y = np.concatenate(ys)\n",
    "    x = np.dstack((x[:, :1024], x[:, 1024:2048], x[:, 2048:]))\n",
    "    x = x.reshape((x.shape[0], 32, 32, 3)).transpose(0,3,1,2)\n",
    "\n",
    "    # subtract per-pixel mean\n",
    "    pixel_mean = np.mean(x[0:50000],axis=0)\n",
    "    #pickle.dump(pixel_mean, open(\"cifar10-pixel_mean.pkl\",\"wb\"))\n",
    "    x -= pixel_mean\n",
    "\n",
    "    # create mirrored images\n",
    "    X_train = x[0:50000,:,:,:]\n",
    "    Y_train = y[0:50000]\n",
    "    X_train_flip = X_train[:,:,:,::-1]\n",
    "    Y_train_flip = Y_train\n",
    "    X_train = np.concatenate((X_train,X_train_flip),axis=0)\n",
    "    Y_train = np.concatenate((Y_train,Y_train_flip),axis=0)\n",
    "\n",
    "    X_test = x[50000:,:,:,:]\n",
    "    Y_test = y[50000:]\n",
    "\n",
    "    return dict(\n",
    "        X_train=lasagne.utils.floatX(X_train),\n",
    "        Y_train=Y_train.astype('int32'),\n",
    "        X_test = lasagne.utils.floatX(X_test),\n",
    "        Y_test = Y_test.astype('int32'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def build_cnn(input_var=None, num_conv = 64, mid_neurons = 256):\n",
    "    # As a third model, we'll create a CNN of two convolution + pooling stages\n",
    "    # and a fully-connected hidden layer in front of the output layer.\n",
    "\n",
    "    # Input layer, as usual:\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 3, 32, 32),\n",
    "                                        input_var=input_var)\n",
    "\n",
    "    network = lasagne.layers.Conv2DLayer( #28*28\n",
    "            network, num_filters=num_conv, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.Orthogonal('relu'))\n",
    "\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=num_conv, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.Orthogonal('relu'))\n",
    "\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters= 2 * num_conv, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.Orthogonal('relu'))\n",
    "\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters= 2 * num_conv, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.Orthogonal('relu'))\n",
    "\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            network,\n",
    "            num_units=mid_neurons,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.Orthogonal('relu'))\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "X_train = data['X_train']\n",
    "Y_train = data['Y_train']\n",
    "X_test = data['X_test']\n",
    "Y_test = data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_flat_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_flat_test = X_test.reshape(X_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_eval( model, train_x, train_y, test_x, test_y ):\n",
    "    model.fit( train_x, train_y )\n",
    "    p = model.predict( test_x )\n",
    "    OA = sum(test_y==p)/len(test_y)\n",
    "    return OA\n",
    "svm=SVC(kernel='linear',C=1,shrinking=False)\n",
    "svm_auc = train_and_eval( svm, X_flat_train, Y_train, \\\n",
    "            X_flat_test, Y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_conv = 32\n",
    "mid_neurons = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomCNN(object):\n",
    "    def __init__(self):\n",
    "        self.svm_acc = []\n",
    "        self.lr_acc = []\n",
    "        \n",
    "    def experiment(self):\n",
    "        input_var = T.tensor4('inputs')\n",
    "        target_var = T.ivector('targets')\n",
    "        network = build_cnn(input_var, num_conv, mid_neurons)\n",
    "        feature_layer = build_cnn(input_var, num_conv, mid_neurons)\n",
    "        feature = lasagne.layers.get_output(feature_layer, deterministic=True)\n",
    "        feature_fn = theano.function([input_var], feature)\n",
    "        train_feature = np.zeros((100000,mid_neurons))\n",
    "        test_feature = np.zeros((10000,mid_neurons))\n",
    "        i = 0\n",
    "        for batch in iterate_minibatches(X_train, Y_train, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            out = feature_fn(inputs)\n",
    "            train_feature[i*500:(i+1)*500,:] = out\n",
    "            i += 1\n",
    "        i = 0\n",
    "        for batch in iterate_minibatches(X_test, Y_test, 500, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            out = feature_fn(inputs)\n",
    "            test_feature[i*500:(i+1)*500,:] = out\n",
    "            i += 1\n",
    "        lr = LR(C=1)\n",
    "        lr_auc = train_and_eval( lr, train_data, y_train, \\\n",
    "            test_data, y_test )\n",
    "        self.lr_acc.append(lr_auc)\n",
    "        svm=sklearn.svm.SVC(kernel='linear',C=1,shrinking=False)\n",
    "        svm_auc = train_and_eval( svm, train_data, y_train, \\\n",
    "            test_data, y_test )\n",
    "        self.svm_acc.append(svm_auc)\n",
    "        print(\"lr accuracy:\\t\\t{:.2f} %  svm accuracy:\\t\\t{:.2f} %\".format(100*lr_auc,100*svm_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randc = RandomCNN()\n",
    "for i in range(5):\n",
    "    randc.experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_conv = 32\n",
    "mid_neurons = 512\n",
    "randc = RandomCNN()\n",
    "for i in range(5):\n",
    "    randc.experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
