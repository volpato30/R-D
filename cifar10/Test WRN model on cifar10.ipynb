{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: TITAN X (Pascal) (CNMeM is disabled, cuDNN 5105)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.updates import nesterov_momentum, adam\n",
    "from lasagne.layers import helper\n",
    "from lasagne.layers import get_output, InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
    "from utils import load_pickle_data_test, load_pickle_data_cv\n",
    "\n",
    "variant = 'wide'\n",
    "depth = 3\n",
    "width = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, X, y, num_units=10):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.input_var = T.matrix('inputs')\n",
    "        self.target_var = T.ivector('targets')\n",
    "        self.l_in = InputLayer(shape=(None, X.shape[1]), input_var=self.input_var)\n",
    "        self.l_out = DenseLayer(self.l_in, num_units=num_units, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "        self.prediction = lasagne.layers.get_output(self.l_out)\n",
    "        self.loss = lasagne.objectives.categorical_crossentropy(self.prediction, self.target_var)\n",
    "        self.loss = self.loss.mean()\n",
    "        self.params = lasagne.layers.get_all_params(self.l_out, trainable=True)\n",
    "        self.updates = lasagne.updates.adadelta(self.loss, self.params, learning_rate=1)\n",
    "        \n",
    "        self.test_prediction = lasagne.layers.get_output(self.l_out, deterministic=True)\n",
    "        self.test_loss = lasagne.objectives.categorical_crossentropy(self.test_prediction,\n",
    "                                                            self.target_var)\n",
    "        self.test_loss = self.test_loss.mean()\n",
    "        self.test_acc = T.mean(T.eq(T.argmax(self.test_prediction, axis=1), self.target_var),\n",
    "                      dtype=theano.config.floatX)\n",
    "        self.train_fn = theano.function([self.input_var, self.target_var],\n",
    "                                        self.loss, updates=self.updates)\n",
    "        self.acc_fn = theano.function([self.input_var, self.target_var], \n",
    "                                      self.test_acc)\n",
    "        self.train()\n",
    "        \n",
    "    def train(self, num_epochs=50, batch_size=1000):\n",
    "        for epoch in range(num_epochs):\n",
    "            train_err = 0\n",
    "            train_batches = 0\n",
    "            for batch in iterate_minibatches(self.X, self.y, batch_size, shuffle=False):\n",
    "                inputs, targets = batch\n",
    "                train_err += self.train_fn(inputs, targets)\n",
    "                train_batches += 1\n",
    "\n",
    "    def eval_acc(self, X_test, y_test):\n",
    "        test_acc = 0\n",
    "        test_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, y_test, 1000, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            test_acc += self.acc_fn(inputs, targets)\n",
    "            test_batches += 1\n",
    "        self.test_acc = test_acc/test_batches\n",
    "        print('overall acc is: {}'.format(self.test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if variant == 'normal':\n",
    "    from models import ResNet_FullPreActivation as ResNet\n",
    "elif variant == 'bottleneck':\n",
    "    from models import ResNet_BottleNeck_FullPreActivation as ResNet\n",
    "elif variant == 'wide':\n",
    "    from models import ResNet_FullPre_Wide as ResNet\n",
    "else:\n",
    "    print ('Unsupported model %s' % variant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "Accuracy on the testing set,  0.9542\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE = 1\n",
    "\n",
    "'''\n",
    "Set up all theano functions\n",
    "'''\n",
    "X = T.tensor4('X')\n",
    "Y = T.ivector('y')\n",
    "\n",
    "# set up theano functions to generate output by feeding data through network, any test outputs should be deterministic\n",
    "# load model\n",
    "if width > 1:\n",
    "    output_layer = ResNet(X, n=depth, k=width)\n",
    "else:\n",
    "    output_layer = ResNet(X, n=depth)\n",
    "output_test = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "\n",
    "output_class = T.argmax(output_test, axis=1)\n",
    "\n",
    "# set up training and prediction functions\n",
    "predict_proba = theano.function(inputs=[X], outputs=output_test)\n",
    "predict_class = theano.function(inputs=[X], outputs=output_class)\n",
    "\n",
    "'''\n",
    "Load data and make predictions\n",
    "'''\n",
    "test_X, test_y = load_pickle_data_test()\n",
    "\n",
    "# load network weights\n",
    "f = gzip.open('weights/%s%d_resnet.pklz'%(variant,depth), 'rb')\n",
    "all_params = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "helper.set_all_param_values(output_layer, all_params)\n",
    "\n",
    "#make predictions\n",
    "pred_labels = []\n",
    "for j in range((test_X.shape[0] + BATCHSIZE - 1) // BATCHSIZE):\n",
    "    sl = slice(j * BATCHSIZE, (j + 1) * BATCHSIZE)\n",
    "    X_batch = test_X[sl]\n",
    "    pred_labels.extend(predict_class(X_batch))\n",
    "\n",
    "pred_labels = np.array(pred_labels)\n",
    "print(pred_labels.shape)\n",
    "\n",
    "'''\n",
    "Compare differences\n",
    "'''\n",
    "same = 0\n",
    "for i in range(pred_labels.shape[0]):\n",
    "    if test_y[i] == pred_labels[i]:\n",
    "        same += 1\n",
    "\n",
    "print('Accuracy on the testing set, ', (float(same) / float(pred_labels.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_list = lasagne.layers.get_all_layers(output_layer)\n",
    "residual_list = [layer for layer in layer_list if isinstance(layer, lasagne.layers.merge.ElemwiseSumLayer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<lasagne.layers.merge.ElemwiseSumLayer at 0x7f5630786fd0>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f5630795fd0>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f56307a3048>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f563072b1d0>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f56307351d0>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f563073d208>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f5630744240>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f563074e278>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f5630754400>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f563075d400>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f5630766438>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f56306ee470>,\n",
       " <lasagne.layers.merge.ElemwiseSumLayer at 0x7f56306f84a8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(residual_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = [residual_list[2], residual_list[7], residual_list[12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_list = lasagne.layers.get_output(test_list)\n",
    "output_fn = theano.function([X], output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 130.59715271  130.01402283  130.915802   ...,  131.06472778\n",
      "    130.38645935  130.18037415]\n",
      "  [ 129.99595642  129.21817017  130.07235718 ...,  130.04629517\n",
      "    129.33551025  129.18457031]\n",
      "  [ 129.65206909  128.61184692  129.34715271 ...,  129.20292664\n",
      "    128.58711243  128.63717651]\n",
      "  ..., \n",
      "  [ 126.54090881  124.57240295  123.92199707 ...,  124.16797638\n",
      "    124.59146881  125.38682556]\n",
      "  [ 127.05977631  125.47117615  125.29917908 ...,  125.40764618\n",
      "    125.47453308  125.90288544]\n",
      "  [ 127.75404358  126.63544464  126.93002319 ...,  126.72489166\n",
      "    126.48709106  126.57411194]]\n",
      "\n",
      " [[ 136.01364136  135.38494873  136.17668152 ...,  136.37138367\n",
      "    135.76266479  135.53540039]\n",
      "  [ 135.25456238  134.39224243  135.0798645  ...,  135.20358276\n",
      "    134.62319946  134.46524048]\n",
      "  [ 134.64434814  133.45162964  133.97103882 ...,  134.01547241\n",
      "    133.59587097  133.65266418]\n",
      "  ..., \n",
      "  [ 125.99935913  123.7685318   122.84073639 ...,  122.9366684\n",
      "    123.65466309  124.74809265]\n",
      "  [ 126.4221344   124.64066315  124.24386597 ...,  124.27906799\n",
      "    124.55282593  125.20968628]\n",
      "  [ 127.02835846  125.75370789  125.87589264 ...,  125.69333649\n",
      "    125.57688904  125.81824493]]\n",
      "\n",
      " [[ 132.59440613  131.8739624   132.58422852 ...,  132.55960083\n",
      "    132.10122681  132.0098877 ]\n",
      "  [ 131.40228271  130.4624176   131.06166077 ...,  131.01812744\n",
      "    130.60922241  130.58911133]\n",
      "  [ 130.31919861  129.02978516  129.43859863 ...,  129.39335632\n",
      "    129.15637207  129.36476135]\n",
      "  ..., \n",
      "  [ 114.24708557  111.87960052  110.83999634 ...,  110.88146973\n",
      "    111.74215698  113.07066345]\n",
      "  [ 114.76382446  112.82113647  112.29075623 ...,  112.28019714\n",
      "    112.71091461  113.61264801]\n",
      "  [ 115.58480072  114.1341095   114.11550903 ...,  113.90613556\n",
      "    113.94993591  114.42662048]]]\n"
     ]
    }
   ],
   "source": [
    "train_X, valid_X, train_y, valid_y = load_pickle_data_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 3, 32, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "batchsize = 500\n",
    "feature_list = [None,None,None]\n",
    "for batch in iterate_minibatches(train_X, train_y, batchsize):\n",
    "    inputs, _ = batch\n",
    "    temp = output_fn(inputs)\n",
    "    for i in range(3):\n",
    "        if feature_list[i] == None:\n",
    "            feature_list[i] = temp[i]\n",
    "        else:\n",
    "            feature_list[i] = np.concatenate((feature_list[i], temp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 128, 32, 32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 256, 16, 16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 512, 8, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('./learned_features/features', feature_list[0], feature_list[1], feature_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature = feature_list[2].reshape(45000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(train_feature, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "batchsize = 500\n",
    "test_feature = None\n",
    "for batch in iterate_minibatches(test_X, test_y, batchsize):\n",
    "    inputs, _ = batch\n",
    "    temp = output_fn(inputs)\n",
    "    if test_feature == None:\n",
    "        test_feature = temp[2]\n",
    "    else:\n",
    "        test_feature = np.concatenate((test_feature, temp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall acc is: 0.9453000009059906\n"
     ]
    }
   ],
   "source": [
    "lr.eval_acc(test_feature.reshape(10000,-1), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
